\chapter*{\centering Introduction}  

A communication network involves the interconnection of a large number of devices, protocols and applications, as well as application, service and user specific Quality of Service (QoS) and Quality of Experience (QoE) requirements: the problem of optimizing the performance of such a complex distributed system while guaranteeing the desired QoS and QoE specifications is a very challenging engineering problem since the heterogeneity and complexity of such network infrastructures pose a number of challenges in effectively modeling, managing and optimizing network resources (e.g. see \cite{Neely2010,Lemeshko2019} and references therein). A Knowledge Plane (KP) approach \cite{Clark2003} has been proposed to enable automation, recommendation and intelligence by applying machine learning and cognitive techniques. However the KP approach has not been prototyped nor deployed because each node of traditional network systems, such as routers or switches, can only view and act over a small portion of the system. This implies that each node can learn only from a (small) part of the complete system and therefore it is very complex to design control algorithms beyond the local domain \cite{Mestres2017}.

The applications of machine learning in networks is become crucial for future developments. Patcha and Park \cite{Patcha2007} have given a detailed description of machine learning techniques in the domain of intrusion detection. Nguyen and Armitage \cite{Nguyen2008} focus on IP traffic classification. Bkassiny et al. \cite{Bkassiny2013} have studied learning problems in Cognitive Radio Networks, and surveyed existing machine learning based methods to address them. How machine learning techniques can be applied in wireless sensor networks has been investigated in \cite{Alsheikh2014}. Wang et al. \cite{Wang2015} have presented the state-of-theart Artificial Intelligence based techniques applied to evolve the heterogeneous networks, and discussed future research challenges. Buczak and Guven \cite{Buczak2016} have researched on data mining methods for cyber security intrusion detection. Klaine et al. \cite{Klaine2017} have surveyed the machine learning algorithms solutions in self organizing cellular networks. How to improve network traffic control by using machine learning techniques has been studied in \cite{Fadlullah2017}. Similar to \cite{Patcha2007}, Hodo et al. \cite{Hodo2017} also focus on machine learning based Intrusion Detection System. Zhou et al. \cite{Zhou2017} focus on using cognitive radio technology with machine learning techniques to enhance spectrum utilization and energy efficiency of wireless networks. Chen et al. \cite{Chen2017} have studied the neural networks solutions applied in wireless networks such as communication, virtual reality and edge caching. Usama et al. \cite{Usama2017} have applied unsupervised learning techniques in the domain of networking. Although machine learning techniques have been applied in various domains, no existing works focus on the applications of machine learning in the domain of Software Defined Network (SDN).

Thanks to the recently introduced SDN paradigm \cite{Sezer2013,Kreutz2015, Jarschel2014, Chen2015, Ameigeiras2015} the control plane and the data plane are decoupled: this enables the possibility of learning (i.e. identifying) dynamical network models to be used for management and optimization purposes. Indeed, in SDN, network resources are managed by a logically centralized controller that owns a global view of the network: this feature provides the capacity of monitoring and collecting, in real-time, data on the network state and configuration as well as packet and flow-granularity information \cite{Amaral2016}. Recent advances in computing technologies such as Graphics Processing Unit and Tensor Processing Unit provide a good opportunity to apply promising machine learning techniques (e.g., deep neural networks) in the network field \cite{Wang2018, Usama2017}. Data is the key to the data-driven machine learning algorithms. The centralized SDN controller has a global network view, and is able to collect various network data. Based on the real-time and historical network data, machine learning techniques can bring intelligence to the SDN controller by performing data analysis, network optimization, and automated provision of network services. The programmability of SDN enables that the optimal network solutions (e.g., configuration and resource allocation) made by machine learning algorithms can be executed on the network in real time.

More in detail, a SDN controller device can configure the forwarding state of each switch by using a standard protocol called OpenFlow (OF) \cite{McKeown2008}. Thanks to the OF \textit{counter variables} (e.g. flow statistics, port statistics, queue statistics, etc.), the controller can retrive information (feedback) from the network devices and store/process them for optimization purposes \cite{OFP13}. A SDN controller can supervise many aspects of traffic flow, as segment routing and queue management on switch ports. In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution.

Indeed, the most difficult challenge to be addressed in order to apply optimization techniques is to derive a predictive model of the queues of the switch behaviour. On this line of research, Cello \textit{et al.} provide in \cite{Cello2016} a predictive model for estimating QoS in order to detect the need for a re-routing strategy due to link saturation. However, this framework cannot be used to apply traffic optimization techniques. In \cite{LeeIEEEToN2007} an initial effort is conducted to derive a general hybrid systems framework to model the flow of traffic in communication networks. In \cite{DiBenedetto2014} the authors provide a first formulation and implementation, based on hybrid systems theory, of a mathematical and simulative environment to formally model the effect of router/link failures on the dynamics of TCP and UDP packet flows belonging to different end-user services (i.e. http, ftp, mailing and video streaming). However, even though hybrid systems are very effective in modelling a network of routers, using such framework for implementing traffic optimization is out of question for computational complexity issues. A further research question focuses on designing strategies for periodic updating of network models, in order to maintain good performance despite the evolution of the real system \cite{Mulinka2018}.

To the best of the author knowledge the state of the art in deriving accurate dynamical models of communication networks still lacks of methods that exploit historical network data to learn (identify) a dynamical network model that can be directly used for optimal control (e.g. of segment routing and/or queue management) and is practical from the computational complexity point of view \cite{Neely2010,Lemeshko2019,Kim2019,Aljoby2019,Lebedenko2018,Le2007,SouravGhosh2005}. In this scenario, computing technologies such as graphic processing and tensor processing units represent a good opportunity to implement advanced control theoretic (e.g. Model Predictive Control - MPC) and machine learning algorithms (e.g. decision trees, deep neural networks, etc.) in the communication networks \cite{Wang2018, Usama2017, Xie2019, Xu2018}. In summary, the real-time programmability of SDN controllers and the availability of massive historical data enable the exploitation of data analysis and optimization techniques for improving networks efficiency and performance.

The goal of this thesis is to address this challenge exploiting control theory combined with Machine Learning techniques. Queues bandwidth control must rely on an accurate model for predicting queues state:
a novel methodology to learn an accurate model of the dynamical input-output behavior of a switch device starting from historical data, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, has been presented as the main contribution of this work. At first a comparison between the prediction accuracy of the proposed technique with respect to Neural Network (NN) models has been shown. Then in a network emulation environment the proposed novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) has been directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services.
%\textcolor{blue}{as the main contribution of this paper we present a novel methodology, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, to learn starting from historical data an accurate model of the dynamical input-output behavior of a switch device. We first compare the prediction accuracy of our technique with respect to Neural Network (NN) models and show in a network emulation environment that our novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) can be directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services. We test a closed loop system based on Model Predictive Control on a SDN network emulation, exploiting the Mininet environment \cite{Mininet} and the D-ITG traffic generator \cite{Avallone2004, Botta2012, Botta2013}. In particular, our D-ITG traffic generator has been configured to produce stochastic traffic whose mean value follows the pattern of a real data set (where packets are differentiated by their Differentiated Services Code Point - DSCP - priority index) extracted from two days logs of a router of a large service provider network.}

The manuscript is organized as follows: a background knowledge about SDN and Machine learning has been introduced in Chapter \ref{sec:SDN_BGK} and in Chapter \ref{sec:ML_BGK} respectively, in Chapter \ref{sec:SDNNetSim} the network emulation environment has been illustrated; in Chapter \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation solvable via Quadratic Programming (QP) has been described; in Chapter \ref{secExpRes} the prediction accuracy and control performance validation using the proposed emulation environment has been provided.