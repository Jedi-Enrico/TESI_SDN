\chapter*{\centering Introduction}  
%
%A communication network involves the interconnection of a large number of devices, protocols and applications, as well as application, service and user specific Quality of Service (QoS) and Quality of Experience (QoE) requirements: the problem of optimizing the performance of such a complex distributed system while guaranteeing the desired QoS and QoE specifications is a very challenging engineering problem since the heterogeneity and complexity of such network infrastructures pose a number of challenges in effectively modeling, managing and optimizing network resources (e.g. see \cite{Neely2010,Lemeshko2019} and references therein). A Knowledge Plane (KP) approach \cite{Clark2003} has been proposed to enable automation, recommendation and intelligence by applying machine learning and cognitive techniques. However the KP approach has not been prototyped nor deployed because each node of traditional network systems, such as routers or switches, can only view and act over a small portion of the system. This implies that each node can learn only from a (small) part of the complete system and therefore it is very complex to design control algorithms beyond the local domain \cite{Mestres2017}.
%
%Thanks to the recently introduced SDN paradigm \cite{Sezer2013,Kreutz2015, Jarschel2014, Chen2015, Ameigeiras2015} the control plane and the data plane are decoupled: this enables the possibility of learning (i.e. identifying) dynamical network models to be used for management and optimization purposes. Indeed, in SDN, network resources are managed by a logically centralized controller that owns a global view of the network: this feature provides the capacity of monitoring and collecting, in real-time, data on the network state and configuration as well as packet and flow-granularity information \cite{Amaral2016}. Recent advances in computing technologies such as Graphics Processing Unit and Tensor Processing Unit provide a good opportunity to apply promising machine learning techniques (e.g., deep neural networks) in the network field \cite{Wang2018, Usama2017}. Data is the key to the data-driven machine learning algorithm: the centralized SDN controller has a global network view, and is able to collect various network data. The potential impact of machine learning in networks is evident from the huge literature on the topic: Patcha and Park \cite{Patcha2007} have given a detailed description of machine learning techniques in the domain of intrusion detection; Nguyen and Armitage \cite{Nguyen2008} focus on IP traffic classification; Bkassiny et al. \cite{Bkassiny2013} have surveyed existing machine learning based methods in Cognitive Radio Networks; \cite{Alsheikh2014} investigated how machine learning techniques can be applied in wireless sensor networks; Wang et al. \cite{Wang2015} have presented the state-of-the-art on Artificial Intelligence based techniques applied to evolve heterogeneous networks and discussed future research challenges; Buczak and Guven \cite{Buczak2016} investigated data mining methods for cyber-security intrusion detection; Klaine et al. \cite{Klaine2017} have surveyed machine learning algorithms for self organizing cellular networks; \cite{Fadlullah2017} investigated how to improve network traffic control using machine learning techniques; Hodo et al. \cite{Hodo2017} focus on machine learning based Intrusion Detection System; Zhou et al. \cite{Zhou2017} focus on cognitive radio technologies enforced by machine learning techniques to enhance spectrum utilization and energy efficiency of wireless networks; Chen et al. \cite{Chen2017} have studied neural networks solutions applied in wireless networks for virtual reality and edge caching; Usama et al. \cite{Usama2017} have applied unsupervised learning techniques in the general domain of networking. Although machine learning techniques have been widely investigated in the communication scientific community, to the best of our knowledge no existing work focuses on the applications of machine learning and control theory for identifying models of network devices in the domain of Software Defined Network (SDN), with the aim of efficiently apply Model Predictive Control.
%
%Based on the real-time and historical network data, machine learning techniques can indeed bring intelligence in the SDN controller by creating network models and performing data analysis, network optimization and automated provision of network services. The programmability of SDN enables that the optimal network solutions (e.g., configuration and resource allocation) made by machine learning algorithms can be executed on the network in real time. More in detail, a SDN controller device can configure the forwarding state of each switch by using a standard protocol called OpenFlow (OF) \cite{McKeown2008}. Thanks to the OF \textit{counter variables} (e.g. flow statistics, port statistics, queue statistics, etc.), the controller can retrive information (feedback) from the network devices and store/process them for optimization purposes \cite{OFP13}. A SDN controller can supervise many aspects of traffic flow, as segment routing and queue management on switch ports. 
%
%In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution. Indeed, the most difficult challenge to be addressed in order to apply optimization techniques is to derive a predictive model of the queues of the switch behaviour. On this line of research, Cello \textit{et al.} provide in \cite{Cello2016} a predictive model for estimating QoS in order to detect the need for a re-routing strategy due to link saturation. However, this framework cannot be used to apply traffic optimization techniques. In \cite{LeeIEEEToN2007} an initial effort is conducted to derive a general hybrid systems framework to model the flow of traffic in communication networks. In \cite{DiBenedetto2014} the authors provide a first formulation and implementation, based on hybrid systems theory, of a mathematical and simulative environment to formally model the effect of router/link failures on the dynamics of TCP and UDP packet flows belonging to different end-user services (i.e. http, ftp, mailing and video streaming). However, even though hybrid systems are very effective in modelling a network of routers, using such framework for implementing traffic optimization is out of question for computational complexity issues. A further research question focuses on designing strategies for periodic updating of network models, in order to maintain good performance despite the evolution of the real system \cite{Mulinka2018}.
%
%Numerous studies have been conducted to maximize the performance of the controller and OpenFlow switch of SDN, however, few results and methodologies exist to model and perform optimal control of SDN switches with priority scheduling. By analyzing the literature regarding the traffic management in SDN and queue with priority more in general, we can distinguish three different approaches:
%
%\begin{itemize}
%  \item \textit{Heuristic approaches}, where algorithms to both identify and control traffic within a queue are based on rule-of-thumbs and empirical approaches that do not take into account any particular model: in \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution; in \cite{Umadevi} authors provide a scheduling algorithm for handling the incoming data traffic by enqueuing packets into the corresponding queue based on priority and High Priority queue is dequeued first; in \cite{Olariu} the authors define multiple queues with different priority classes, which are used to prioritize VoIP packet based on delay, and the controller decides where to enqueue the packet based on delay and considering 5 different decision thresholds.
%  
%  \item \textit{Parametric approaches}, where the control of queues is based on less heuristics and more objective methods. More precisely, one of more parameters that describe the QoS of an SDN are chosen and optimization is performed based on \textit{static} models characterised by such parameters: both in \cite{Haiyan} and \cite{ChenWang} the authors consider different approaches to model and control queuing delays with specific network parameters; in \cite{Najjar} QoE is taken into account in the context of VOIP and the decision metric for selecting the best link for establishing a new VoIP call is based on the MOS quality metric, which is a typical measure of the level of a user's satisfaction of the quality of a call. These approaches despite the fact that are easy to understand and to implement, may not be often suitable to describe and control traffic flows in large and complex networks as they are not based on a \textit{dynamical} network model.
%  
%  \item \textit{Model-based approach}, where a \textit{dynamical} mathematical model of packet flows within a queue is considered, is the one most related to the research conducted in this Thesis. In the classical literature of queuing theory, in particular applied to SDN, most of the approaches are based on classic structures for models \cite{MDPSDNSURV} and many techinques are exploited to estimate the parameters and the state of a queue \cite{ParameterStateEst}. In \cite{Sood2016PerformanceAO}, the authors emphasized that switch performance depends on multiple factors such as: flow-table size, packet arrival rate, etc., and they took these key factors into account for the design of their M/Geo/1 system where the arriving packets follow a Poisson distribution and the service times follows a Geometric distribution; in \cite{SINGH201824}, beside describing a comprehensive review of the literature (mostly M/M/k and M/G/k), authors derived a new model for a queueing network, based on Quasi Bird Death (QBD) processes; another approach based on a dynamical model for Model Predictive Control is described in \cite{SchoffMPC}, where the authors derive a Discrete Time Markov Jump Linear System to model a queueing network with the aim of defining predictive control policies based on MPC; finally, in \cite{WANG2012120} the author proposes a new congestion control algorithm based on MPC, called MPAQM, where the queue length is predicted based on the extended TCP/AQM system model and a state estimator. The main drawback of the approach proposed by the authors here is that they linearize and discretize the model of a TCP/AQM interconnection system as illustrated in \cite{TCPSTATESPACE}; Nonlinear MPC can be applied, but the problem is that the resulting optimization problem can be nonconvex and so hard to solve. In such scenarios, linearization is a solution but not always a good solution because of the fact that linearize a model of a complex system not always ensure adequate control performance, especially when the system is going to operate far from of the linearization point.
%%  
%% \textbf{Non ho capito questo ultimo paragrafo: se fanno linearizzazione, perche' si potrebbe usare MPC non lineare? La parte dopo, che dice che con la linearizzazione si possono avere problemi, mi sembra invece giusta. Forse si deve prima dire che la linearizzazione non funziona sempre, e spostare alla fine la frase su nonlinear MPC spiegando pero' che AL POSTO della linearizzazione si puo' direttamente applicare nonlinear MPC, che pero' ha i suoi problemi...giusto?}
%  \end{itemize}
%
%
%Obviously the most interesting are the Model-based approaches. However, their main drawback is related to the identification of the model. One issue is related to the need of having access to the queue's buffer data to identify the model and, at least with commercial hardware, this is not possible in general. A second issue is that classical models, such as the ones previously discussed, are usually designed to provide best accuracy for one step prediction. When applying MPC one wants to forecast and exploit the value of state variables for multiple steps ahead: using classical approaches this is achieved by using the prediction computed at $k+1$ to predict the state at $k+2$, and so on. This approach is not always accurate when a long prediction horizon is considered, since many additional issues arise such as error propagation and increased uncertainty. In such situations, a multiple output strategy where a model is able to directly predict the state at different future time steps, or one model for each time step as we will propose in this work, can increase the MPC performance. Of course this comes with additional computational complexity, especially when the number of time steps to be forecasted increases: however, will be shown later on, this is not an issue in our methodology since the future predictions can be computed exploiting the advantages of binary decision trees and parallel computation.
%The last and most important issue is that the mathematical models proposed in such literature does not allow to directly exploit Model Predictive Control methods with, simultaneously, good accuracy and a realistically implementable computational complexity, i.e. using Quadratic Programming (QP) solvers. Tackling such research challenges is the main topic of this Thesis. Indeed, to the best of the author's knowledge, the state of the art in deriving accurate dynamical models of communication networks still lacks of methods that exploit historical network data to learn (identify) a dynamical network model that can be directly used for optimal control (e.g. of segment routing and/or queue management) and is practical from the computational complexity point of view \cite{Neely2010,Lemeshko2019,Kim2019,Aljoby2019,Lebedenko2018,Le2007,SouravGhosh2005}.
%
%In this scenario, computing technologies such as graphic processing and tensor processing units represent a good opportunity to implement advanced control theoretic (e.g. Model Predictive Control - MPC) and machine learning algorithms (e.g. decision trees, deep neural networks, etc.) in the communication networks \cite{Wang2018, Usama2017, Xie2019, Xu2018}. In summary, the real-time programmability of SDN controllers and the availability of massive historical data enable the exploitation of data analysis and optimization techniques for improving networks efficiency and performance.
%
%The goal of this thesis is to address this challenge exploiting control theory combined with Machine Learning techniques. Queues bandwidth control must rely on an accurate model for predicting queues state: a novel methodology to learn an accurate model of the dynamical input-output behavior of a switch device starting from historical data, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, has been presented as the main contribution of this Thesis. At first a comparison between the prediction accuracy of the proposed technique with respect to Neural Network (NN) models has been shown. Then in a network emulation environment the proposed novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) has been directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services.
%%\textcolor{blue}{as the main contribution of this paper we present a novel methodology, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, to learn starting from historical data an accurate model of the dynamical input-output behavior of a switch device. We first compare the prediction accuracy of our technique with respect to Neural Network (NN) models and show in a network emulation environment that our novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) can be directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services. We test a closed loop system based on Model Predictive Control on a SDN network emulation, exploiting the Mininet environment \cite{Mininet} and the D-ITG traffic generator \cite{Avallone2004, Botta2012, Botta2013}. In particular, our D-ITG traffic generator has been configured to produce stochastic traffic whose mean value follows the pattern of a real data set (where packets are differentiated by their Differentiated Services Code Point - DSCP - priority index) extracted from two days logs of a router of a large service provider network.}
%
%The manuscript is organized as follows: a background knowledge about SDN and Machine learning has been introduced in Chapter \ref{sec:SDN_BGK} and in Chapter \ref{sec:ML_BGK} respectively; in Chapter \ref{sec:SDNNetSim} the network emulation environment has been illustrated; in Chapter \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation solvable via Quadratic Programming (QP) has been described; in Chapter \ref{secExpRes} the prediction accuracy and control performance validation using the proposed emulation environment has been provided.
%
%
%%A communication network involves the interconnection of a large number of devices, protocols and applications, as well as application, service and user specific Quality of Service (QoS) and Quality of Experience (QoE) requirements: the problem of optimizing the performance of such a complex distributed system while guaranteeing the desired QoS and QoE specifications is a very challenging engineering problem since the heterogeneity and complexity of such network infrastructures pose a number of challenges in effectively modeling, managing and optimizing network resources (e.g. see \cite{Neely2010,Lemeshko2019} and references therein). A Knowledge Plane (KP) approach \cite{Clark2003} has been proposed to enable automation, recommendation and intelligence by applying machine learning and cognitive techniques. However the KP approach has not been prototyped nor deployed because each node of traditional network systems, such as routers or switches, can only view and act over a small portion of the system. This implies that each node can learn only from a (small) part of the complete system and therefore it is very complex to design control algorithms beyond the local domain \cite{Mestres2017}.
%%
%%The applications of machine learning in networks is become crucial for future developments. Patcha and Park \cite{Patcha2007} have given a detailed description of machine learning techniques in the domain of intrusion detection. Nguyen and Armitage \cite{Nguyen2008} focus on IP traffic classification. Bkassiny et al. \cite{Bkassiny2013} have studied learning problems in Cognitive Radio Networks, and surveyed existing machine learning based methods to address them. How machine learning techniques can be applied in wireless sensor networks has been investigated in \cite{Alsheikh2014}. Wang et al. \cite{Wang2015} have presented the state-of-the art Artificial Intelligence based techniques applied to evolve the heterogeneous networks, and discussed future research challenges. Buczak and Guven \cite{Buczak2016} have researched on data mining methods for cyber security intrusion detection. Klaine et al. \cite{Klaine2017} have surveyed the machine learning algorithms solutions in self organizing cellular networks. How to improve network traffic control by using machine learning techniques has been studied in \cite{Fadlullah2017}. Hodo et al. \cite{Hodo2017} focus on machine learning based Intrusion Detection System. Zhou et al. \cite{Zhou2017} focus on using cognitive radio technology with machine learning techniques to enhance spectrum utilization and energy efficiency of wireless networks. Chen et al. \cite{Chen2017} have studied the neural networks solutions applied in wireless networks such as communication, virtual reality and edge caching. Usama et al. \cite{Usama2017} have applied unsupervised learning techniques in the domain of networking.
%%%Although machine learning techniques have been applied in various domains, no existing works focus on the applications of machine learning in the domain of Software Defined Network (SDN).
%%
%%Thanks to the recently introduced SDN paradigm \cite{Sezer2013,Kreutz2015, Jarschel2014, Chen2015, Ameigeiras2015} the control plane and the data plane are decoupled: this enables the possibility of learning (i.e. identifying) dynamical network models to be used for management and optimization purposes. Indeed, in SDN, network resources are managed by a logically centralized controller that owns a global view of the network: this feature provides the capacity of monitoring and collecting, in real-time, data on the network state and configuration as well as packet and flow-granularity information \cite{Amaral2016}. Recent advances in computing technologies such as Graphics Processing Unit and Tensor Processing Unit provide a good opportunity to apply promising machine learning techniques (e.g., deep neural networks) in the network field \cite{Wang2018, Usama2017}. Data is the key to the data-driven machine learning algorithms. The centralized SDN controller has a global network view, and is able to collect various network data. Based on the real-time and historical network data, machine learning techniques can bring intelligence to the SDN controller by performing data analysis, network optimization, and automated provision of network services. The programmability of SDN enables that the optimal network solutions (e.g., configuration and resource allocation) made by machine learning algorithms can be executed on the network in real time.
%%
%%More in detail, a SDN controller device can configure the forwarding state of each switch by using a standard protocol called OpenFlow (OF) \cite{McKeown2008}. Thanks to the OF \textit{counter variables} (e.g. flow statistics, port statistics, queue statistics, etc.), the controller can retrive information (feedback) from the network devices and store/process them for optimization purposes \cite{OFP13}. A SDN controller can supervise many aspects of traffic flow, as segment routing and queue management on switch ports. In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution.
%%
%%Indeed, the most difficult challenge to be addressed in order to apply optimization techniques is to derive a predictive model of the queues of the switch behaviour. On this line of research, Cello \textit{et al.} provide in \cite{Cello2016} a predictive model for estimating QoS in order to detect the need for a re-routing strategy due to link saturation. However, this framework cannot be used to apply traffic optimization techniques. In \cite{LeeIEEEToN2007} an initial effort is conducted to derive a general hybrid systems framework to model the flow of traffic in communication networks. In \cite{DiBenedetto2014} the authors provide a first formulation and implementation, based on hybrid systems theory, of a mathematical and simulative environment to formally model the effect of router/link failures on the dynamics of TCP and UDP packet flows belonging to different end-user services (i.e. http, ftp, mailing and video streaming). However, even though hybrid systems are very effective in modelling a network of routers, using such framework for implementing traffic optimization is out of question for computational complexity issues. A further research question focuses on designing strategies for periodic updating of network models, in order to maintain good performance despite the evolution of the real system \cite{Mulinka2018}.
%%
%%Numerous studies have been conducted to maximize the performance of the controller and OpenFlow switch of SDN, however, few results and methodologies exist to model and perform optimal control of SDN switches with priority scheduling. By analyzing the literature regarding the traffic management in SDN and queue with priority more in general, we distinguish three different approaches:  "An empirical approach", where algorithms to both identify and control traffic within a queue are based on rule of thumbs or simple approaches that does not take into consideration any particular parameter or model. In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution. In \cite{Umadevi} authors provide a scheduling algorithm for handling the incoming data traffic by enqueuing packets into the corresponding queue based on priority. High Priority queue is dequeued first. In \cite{Olariu}, authors define multiple queues with different priority classes, which are used to prioritize VoIP packet based on delay. The controller decides where to enqueue the packet based on delay and considering 5 different decision thresholds. "A parametric Approach", where the control of queues is based on less heuristic and more objective methods: one of more parameters, that describes the QoS of an SDN are chosen and optimization is done based on static carachterization of such parameters. Both in \cite{Haiyan} and \cite{ChenWang} authors consider different approaches to model and control queuing delays with specific network parameters.In \cite{Najjar} QoE is taken into consideration in the context of VOIP: the decision metric for selecting the best link for establishing a new VoIP call is based on the MOS quality metric which is a typical measure of the level of a user’s satisfaction of the quality of a call. These approaches despite the fact that they are easy to understand and to implement, may not be often suitable to describe and control traffic flows in very big and complex networks. "Model Based Approach", where a dynamical mathematical characterization of the packets flowing within a queue is taken into account. In the classic literature of queuing theory, in particular applied to SDN, most of the approaches are based on classic structures for models, \cite{MDPSDNSURV} and many techinques are exploited to estimate the parameters and the state of a queue \cite{ParameterStateEst}. The main problems we address for these types of approaches are related to the identification of the parameters of the models because, one has to access to the queue's buffer and often, at least with commercial hardware, it is not possible to obtain these measures. Moreover, the formulation proposed in literature are not suitable to be exploited for Model Predictive Control as we do in our work. In \cite{Sood2016PerformanceAO}, authors emphasized that switch performance depends on multiple factors such as: flow-table size, packet arrival rate, etc; they took these key factors into account for the design of their M/Geo/1 system where the arriving packets follow a Poisson distribution and the service times follows a Geometric distribution. In \cite{SINGH201824}, beside describing a comprehensive review of the literature (mostly M/M/k and M/G/k), authors derived a new model for a queueing network, based on Quasi Bird Death (QBD) processes. In \cite{WANG2012120} author propose a new congestion control algorithm based on MPC, called MPAQM. In this work, the queue length is predicted based on the extended TCP/AQM system model and a state estimator. The main drawback of the approach proposed by the authors here is that they linearized and discretized the model of a TCP/AQM interconnection system illustrated in \cite{TCPSTATESPACE}; Nonlinear MPC can be done, but the problem is that the resulting optimization problem can be nonconvex and so hard to solve. In such scenarios, linearization is a solution but not always a good solution because of the fact that linearize a model of a complex system not always ensure adequate control performance, especially when the system is going to operate far from of the linearization point. Another approach based on a dynamical model for Model Predictive Control is described in \cite{SchoffMPC}, where authors derive a Discrete Time Markov Jump Linear System to model a queueing network with the aim of defining predictive control policies, based on MPC.
%%
%%To the best of the author knowledge the state of the art in deriving accurate dynamical models of communication networks still lacks of methods that exploit historical network data to learn (identify) a dynamical network model that can be directly used for optimal control (e.g. of segment routing and/or queue management) and is practical from the computational complexity point of view \cite{Neely2010,Lemeshko2019,Kim2019,Aljoby2019,Lebedenko2018,Le2007,SouravGhosh2005}. In this scenario, computing technologies such as graphic processing and tensor processing units represent a good opportunity to implement advanced control theoretic (e.g. Model Predictive Control - MPC) and machine learning algorithms (e.g. decision trees, deep neural networks, etc.) in the communication networks \cite{Wang2018, Usama2017, Xie2019, Xu2018}. In summary, the real-time programmability of SDN controllers and the availability of massive historical data enable the exploitation of data analysis and optimization techniques for improving networks efficiency and performance.
%%
%%The goal of this thesis is to address this challenge exploiting control theory combined with Machine Learning techniques. Queues bandwidth control must rely on an accurate model for predicting queues state:
%%a novel methodology to learn an accurate model of the dynamical input-output behavior of a switch device starting from historical data, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, has been presented as the main contribution of this work. At first a comparison between the prediction accuracy of the proposed technique with respect to Neural Network (NN) models has been shown. Then in a network emulation environment the proposed novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) has been directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services.
%%%\textcolor{blue}{as the main contribution of this paper we present a novel methodology, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, to learn starting from historical data an accurate model of the dynamical input-output behavior of a switch device. We first compare the prediction accuracy of our technique with respect to Neural Network (NN) models and show in a network emulation environment that our novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) can be directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services. We test a closed loop system based on Model Predictive Control on a SDN network emulation, exploiting the Mininet environment \cite{Mininet} and the D-ITG traffic generator \cite{Avallone2004, Botta2012, Botta2013}. In particular, our D-ITG traffic generator has been configured to produce stochastic traffic whose mean value follows the pattern of a real data set (where packets are differentiated by their Differentiated Services Code Point - DSCP - priority index) extracted from two days logs of a router of a large service provider network.}
%%
%%The manuscript is organized as follows: a background knowledge about SDN and Machine learning has been introduced in Chapter \ref{sec:SDN_BGK} and in Chapter \ref{sec:ML_BGK} respectively; in Chapter \ref{sec:SDNNetSim} the network emulation environment has been illustrated; in Chapter \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation solvable via Quadratic Programming (QP) has been described; in Chapter \ref{secExpRes} the prediction accuracy and control performance validation using the proposed emulation environment has been provided.
%\section*{Intro Paper}
A communication network involves the interconnection of a large number of devices, protocols and applications, as well as application-, service- and user-specific Quality of Service (QoS) and Quality of Experience (QoE) requirements: the problem of optimizing the performance of such a complex distributed system while guaranteeing the desired QoS and QoE specifications is a very challenging engineering problem since the heterogeneity and complexity of such network infrastructures pose a number of challenges in effectively modeling, managing and optimizing network resources (e.g. see \cite{Neely2010,Lemeshko2019} and references therein).

Thanks to the recently introduced Software Defined Network (SDN) paradigm \cite{Kreutz2015} the control plane and the data plane are decoupled: this enables the possibility of learning (i.e. identifying) dynamical network models to be used for management and optimization purposes. Indeed, in SDN, network resources are managed by a logically centralized controller that have a global view of the network: this feature provides the capacity of monitoring and collecting, in real-time, data on the network state and configuration as well as packet and flow-granularity information \cite{Amaral2016}. More in detail, a SDN controller device can configure the forwarding state of each switch by using a standard protocol called OpenFlow (OF) \cite{McKeown2008}. Thanks to the OF \textit{counter variables} (e.g. flow statistics, port statistics, queue statistics, etc.), the controller can retrive information (feedback) from the network devices and store/process them for optimization purposes \cite{OFP13}. A SDN controller can supervise many aspects of traffic flow, as segment routing and queue management on switch ports.

Indeed, the most difficult challenge to be addressed in order to apply optimization techniques is to derive a predictive model of the queues of the switch behaviour. To the best of the author knowledge the state of the art in deriving accurate dynamical models of communication networks still lacks of methods that exploit historical network data to learn (identify) a dynamical network model that can be directly used for optimal control (e.g. of segment routing and/or queue management) and is practical from the computational complexity point of view.

The goal of this research is exploiting control theory combined with Machine Learning techniques to compute an accurate model for predicting queues state inside a switch ports, and use this model to optimally control queues scheduling via bandwidth allocation. In particular, a novel methodology to learn an accurate model of the dynamical input-output behavior of a switch device starting from historical data, that combines ARX identification with Regression Trees (RT) and Random Forests (RF) algorithms \cite{Carner2017, Jain2016, Pasquini2017}, has been presented as the main contribution \cite{EuCNC2020}. At first a comparison between the prediction accuracy of the proposed technique with respect to Neural Network (NN) models has been shown. Then in a network emulation environment the proposed novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization from the computational complexity viewpoint) has been directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services. We validate our approach both on real traffic data and on an emulative setup.

%In particular, in this thesis our previous work \cite{EuCNC2020} has been extended in the following aspects: (1) the effect of iterative model updates using on-the-fly new data in the prediction accuracy is demonstrated; (2) the effect of predictive models of future incoming traffic has been tested; (3) the accuracy of our predictive models has been validated over a real dataset obtained from measurements of the network of an Italian internet service provider (Sonicatel S.r.l.).

The manuscript is organized as follows: a background knowledge about SDN and Machine learning has been introduced in Section \ref{sec:SDN_BGK} and in Section \ref{sec:ML_BGK} respectively and in Section \ref{RelWorks} a survey on related works is provided; in Section \ref{sec:SDNNetSim} the network emulation environment has been illustrated; in Section \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation solvable via Quadratic Programming (QP) has been described; in Section \ref{secExpRes} the prediction accuracy and control performance validation using the proposed emulation environment has been provided.

%The paper is organized as follows: in Section \ref{RelWorks} a survey on related works is provided; in Section \ref{sec:SDNNetSim} the network emulation environment is illustrated; in Section \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation, solvable via Quadratic Programming (QP) is described; in Section \ref{secExpRes} prediction accuracy and control performance validation is provided, using both the proposed emulation environment and real network measurements.

