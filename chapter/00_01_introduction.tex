\chapter*{\centering Introduction}  

A communication network involves the interconnection of a large number of devices, protocols and applications, as well as application, service and user specific Quality of Service (QoS) and Quality of Experience (QoE) requirements: the problem of optimizing the performance of such a complex distributed system while guaranteeing the desired QoS and QoE specifications is a very challenging engineering problem since the heterogeneity and complexity of such network infrastructures pose a number of challenges in effectively modeling, managing and optimizing network resources (e.g. see \cite{Neely2010,Lemeshko2019} and references therein). A Knowledge Plane (KP) approach \cite{Clark2003} has been proposed to enable automation, recommendation and intelligence by applying machine learning and cognitive techniques. However the KP approach has not been prototyped nor deployed because each node of traditional network systems, such as routers or switches, can only view and act over a small portion of the system. This implies that each node can learn only from a (small) part of the complete system and therefore it is very complex to design control algorithms beyond the local domain \cite{Mestres2017}.

The applications of machine learning in networks is become crucial for future developments. Patcha and Park \cite{Patcha2007} have given a detailed description of machine learning techniques in the domain of intrusion detection. Nguyen and Armitage \cite{Nguyen2008} focus on IP traffic classification. Bkassiny et al. \cite{Bkassiny2013} have studied learning problems in Cognitive Radio Networks, and surveyed existing machine learning based methods to address them. How machine learning techniques can be applied in wireless sensor networks has been investigated in \cite{Alsheikh2014}. Wang et al. \cite{Wang2015} have presented the state-of-the art Artificial Intelligence based techniques applied to evolve the heterogeneous networks, and discussed future research challenges. Buczak and Guven \cite{Buczak2016} have researched on data mining methods for cyber security intrusion detection. Klaine et al. \cite{Klaine2017} have surveyed the machine learning algorithms solutions in self organizing cellular networks. How to improve network traffic control by using machine learning techniques has been studied in \cite{Fadlullah2017}. Hodo et al. \cite{Hodo2017} focus on machine learning based Intrusion Detection System. Zhou et al. \cite{Zhou2017} focus on using cognitive radio technology with machine learning techniques to enhance spectrum utilization and energy efficiency of wireless networks. Chen et al. \cite{Chen2017} have studied the neural networks solutions applied in wireless networks such as communication, virtual reality and edge caching. Usama et al. \cite{Usama2017} have applied unsupervised learning techniques in the domain of networking.
%Although machine learning techniques have been applied in various domains, no existing works focus on the applications of machine learning in the domain of Software Defined Network (SDN).

Thanks to the recently introduced SDN paradigm \cite{Sezer2013,Kreutz2015, Jarschel2014, Chen2015, Ameigeiras2015} the control plane and the data plane are decoupled: this enables the possibility of learning (i.e. identifying) dynamical network models to be used for management and optimization purposes. Indeed, in SDN, network resources are managed by a logically centralized controller that owns a global view of the network: this feature provides the capacity of monitoring and collecting, in real-time, data on the network state and configuration as well as packet and flow-granularity information \cite{Amaral2016}. Recent advances in computing technologies such as Graphics Processing Unit and Tensor Processing Unit provide a good opportunity to apply promising machine learning techniques (e.g., deep neural networks) in the network field \cite{Wang2018, Usama2017}. Data is the key to the data-driven machine learning algorithms. The centralized SDN controller has a global network view, and is able to collect various network data. Based on the real-time and historical network data, machine learning techniques can bring intelligence to the SDN controller by performing data analysis, network optimization, and automated provision of network services. The programmability of SDN enables that the optimal network solutions (e.g., configuration and resource allocation) made by machine learning algorithms can be executed on the network in real time.

More in detail, a SDN controller device can configure the forwarding state of each switch by using a standard protocol called OpenFlow (OF) \cite{McKeown2008}. Thanks to the OF \textit{counter variables} (e.g. flow statistics, port statistics, queue statistics, etc.), the controller can retrive information (feedback) from the network devices and store/process them for optimization purposes \cite{OFP13}. A SDN controller can supervise many aspects of traffic flow, as segment routing and queue management on switch ports. In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution.

Indeed, the most difficult challenge to be addressed in order to apply optimization techniques is to derive a predictive model of the queues of the switch behaviour. On this line of research, Cello \textit{et al.} provide in \cite{Cello2016} a predictive model for estimating QoS in order to detect the need for a re-routing strategy due to link saturation. However, this framework cannot be used to apply traffic optimization techniques. In \cite{LeeIEEEToN2007} an initial effort is conducted to derive a general hybrid systems framework to model the flow of traffic in communication networks. In \cite{DiBenedetto2014} the authors provide a first formulation and implementation, based on hybrid systems theory, of a mathematical and simulative environment to formally model the effect of router/link failures on the dynamics of TCP and UDP packet flows belonging to different end-user services (i.e. http, ftp, mailing and video streaming). However, even though hybrid systems are very effective in modelling a network of routers, using such framework for implementing traffic optimization is out of question for computational complexity issues. A further research question focuses on designing strategies for periodic updating of network models, in order to maintain good performance despite the evolution of the real system \cite{Mulinka2018}.

Numerous studies have been conducted to maximize the performance of the controller and OpenFlow switch of SDN, however, few results and methodologies exist to model and perform optimal control of SDN switches with priority scheduling. By analyzing the literature regarding the traffic management in SDN and queue with priority more in general, we distinguish three different approaches:  "An empirical approach", where algorithms to both identify and control traffic within a queue are based on rule of thumbs or simple approaches that does not take into consideration any particular parameter or model. In \cite{Boero2016} a heuristic method is proposed to balance the packet load among queues in order to reduce packet losses, which does not aim at providing an optimal solution. In \cite{Umadevi} authors provide a scheduling algorithm for handling the incoming data traffic by enqueuing packets into the corresponding queue based on priority. High Priority queue is dequeued first. In \cite{Olariu}, authors define multiple queues with different priority classes, which are used to prioritize VoIP packet based on delay. The controller decides where to enqueue the packet based on delay and considering 5 different decision thresholds. "A parametric Approach", where the control of queues is based on less heuristic and more objective methods: one of more parameters, that describes the QoS of an SDN are chosen and optimization is done based on static carachterization of such parameters. Both in \cite{Haiyan} and \cite{ChenWang} authors consider different approaches to model and control queuing delays with specific network parameters.In \cite{Najjar} QoE is taken into consideration in the context of VOIP: the decision metric for selecting the best link for establishing a new VoIP call is based on the MOS quality metric which is a typical measure of the level of a userâ€™s satisfaction of the quality of a call. These approaches despite the fact that they are easy to understand and to implement, may not be often suitable to describe and control traffic flows in very big and complex networks. "Model Based Approach", where a dynamical mathematical characterization of the packets flowing within a queue is taken into account. In the classic literature of queuing theory, in particular applied to SDN, most of the approaches are based on classic structures for models, \cite{MDPSDNSURV} and many techinques are exploited to estimate the parameters and the state of a queue \cite{ParameterStateEst}. The main problems we address for these types of approaches are related to the identification of the parameters of the models because, one has to access to the queue's buffer and often, at least with commercial hardware, it is not possible to obtain these measures. Moreover, the formulation proposed in literature are not suitable to be exploited for Model Predictive Control as we do in our work. In \cite{Sood2016PerformanceAO}, authors emphasized that switch performance depends on multiple factors such as: flow-table size, packet arrival rate, etc; they took these key factors into account for the design of their M/Geo/1 system where the arriving packets follow a Poisson distribution and the service times follows a Geometric distribution. In \cite{SINGH201824}, beside describing a comprehensive review of the literature (mostly M/M/k and M/G/k), authors derived a new model for a queueing network, based on Quasi Bird Death (QBD) processes. In \cite{WANG2012120} author propose a new congestion control algorithm based on MPC, called MPAQM. In this work, the queue length is predicted based on the extended TCP/AQM system model and a state estimator. The main drawback of the approach proposed by the authors here is that they linearized and discretized the model of a TCP/AQM interconnection system illustrated in \cite{TCPSTATESPACE}; Nonlinear MPC can be done, but the problem is that the resulting optimization problem can be nonconvex and so hard to solve. In such scenarios, linearization is a solution but not always a good solution because of the fact that linearize a model of a complex system not always ensure adequate control performance, especially when the system is going to operate far from of the linearization point. Another approach based on a dynamical model for Model Predictive Control is described in \cite{SchoffMPC}, where authors derive a Discrete Time Markov Jump Linear System to model a queueing network with the aim of defining predictive control policies, based on MPC.

To the best of the author knowledge the state of the art in deriving accurate dynamical models of communication networks still lacks of methods that exploit historical network data to learn (identify) a dynamical network model that can be directly used for optimal control (e.g. of segment routing and/or queue management) and is practical from the computational complexity point of view \cite{Neely2010,Lemeshko2019,Kim2019,Aljoby2019,Lebedenko2018,Le2007,SouravGhosh2005}. In this scenario, computing technologies such as graphic processing and tensor processing units represent a good opportunity to implement advanced control theoretic (e.g. Model Predictive Control - MPC) and machine learning algorithms (e.g. decision trees, deep neural networks, etc.) in the communication networks \cite{Wang2018, Usama2017, Xie2019, Xu2018}. In summary, the real-time programmability of SDN controllers and the availability of massive historical data enable the exploitation of data analysis and optimization techniques for improving networks efficiency and performance.

The goal of this thesis is to address this challenge exploiting control theory combined with Machine Learning techniques. Queues bandwidth control must rely on an accurate model for predicting queues state:
a novel methodology to learn an accurate model of the dynamical input-output behavior of a switch device starting from historical data, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, has been presented as the main contribution of this work. At first a comparison between the prediction accuracy of the proposed technique with respect to Neural Network (NN) models has been shown. Then in a network emulation environment the proposed novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) has been directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services.
%\textcolor{blue}{as the main contribution of this paper we present a novel methodology, that combines ARX identification with regression trees and random forests algorithms \cite{Carner2017, Jain2016, Pasquini2017}, to learn starting from historical data an accurate model of the dynamical input-output behavior of a switch device. We first compare the prediction accuracy of our technique with respect to Neural Network (NN) models and show in a network emulation environment that our novel identification technique (differently from NNs, that provide nonlinear predictive models that are impractical for optimization) can be directly and efficiently used to control the bandwidth of the queues of switch ports with the final aim of reducing packet losses, and thus improving QoS, taking into account the priority of different services. We test a closed loop system based on Model Predictive Control on a SDN network emulation, exploiting the Mininet environment \cite{Mininet} and the D-ITG traffic generator \cite{Avallone2004, Botta2012, Botta2013}. In particular, our D-ITG traffic generator has been configured to produce stochastic traffic whose mean value follows the pattern of a real data set (where packets are differentiated by their Differentiated Services Code Point - DSCP - priority index) extracted from two days logs of a router of a large service provider network.}

The manuscript is organized as follows: a background knowledge about SDN and Machine learning has been introduced in Chapter \ref{sec:SDN_BGK} and in Chapter \ref{sec:ML_BGK} respectively; in Chapter \ref{sec:SDNNetSim} the network emulation environment has been illustrated; in Chapter \ref{secSwitchedModeling} the model identification technique and its embedding in a MPC problem formulation solvable via Quadratic Programming (QP) has been described; in Chapter \ref{secExpRes} the prediction accuracy and control performance validation using the proposed emulation environment has been provided.